{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e481238a-e6ea-431d-b2a7-957600884500",
   "metadata": {},
   "source": [
    "# Иллюстрация загрузки и подготовки данных Netflix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3607d22-edeb-445a-b281-8bc237e86a98",
   "metadata": {},
   "source": [
    "### $\\textbf{Содержание}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c60e1bb-1f79-47b0-9cb4-1240e29f2d7a",
   "metadata": {},
   "source": [
    "### $\\textbf{I. Создание табличных данных на основании txt файлов}$\n",
    "### Из записей txt файлов формируются в табличные данные csv формата с атрибутами:\n",
    "#### - $\\it{movie\\_Id} \\in \\mathbb{N}$: идентификатор предложения; \n",
    "#### - $\\it{user_\\_i_d} \\in \\mathbb{N}$: идентификатор пользователя;\n",
    "#### - $\\it{rating} \\in [1, 5]$: полезность предложения для пользователя;\n",
    "#### - $\\it{date} \\in \\mathbb{N}$: временная метка;\n",
    "------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a920d-f5a1-4770-80b5-80d8959acc21",
   "metadata": {},
   "source": [
    "### $\\textbf{II. Обработка фильмов}$\n",
    "### Из названия фильмов генерируются следующие признаки:\n",
    "#### - год выпуска фильма $\\it{year} \\in \\mathbb{N}$;\n",
    "### Из оценок, выставленных пользователями, генерируются следующие признаки:\n",
    "#### - средняя оценка фильма $\\it{rating\\_avg} \\in [0, 5]$;\n",
    "#### - количество оценок фильма $\\it{rating\\_cnt} \\in \\mathbb{N} \\cup \\{0\\}$;\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272be4e1-9592-4d71-8211-18c94b840c3a",
   "metadata": {},
   "source": [
    "### $\\textbf{III. Обработка рейтингов}$\n",
    "#### Никакие признаки на это этапе не генерируются;\n",
    "#### Атрибут даты приводятся к формату timestamp;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51300d1-d5c1-425a-aef5-a2f5c00483ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(\"processingApp\")\\\n",
    "    .config(\"spark.driver.memory\", \"8G\")\\\n",
    "    .config(\"spark.executor.cores\", \"8G\")\\\n",
    "    .config(\"spark.executor.memory\", \"2G\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8354c1e-a4d2-4cc6-810a-5e76e7b8c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = r'./'\n",
    "row_data_files = ['combined_data_' + str(i) + '.txt' for i in range(1,5)]\n",
    "\n",
    "movie_titles_path = r'./movie_titles.csv'\n",
    "\n",
    "save_file_name =  r\"./data_clean/netflix_full.csv\"\n",
    "\n",
    "save_movies = r'./data_clean/movies.csv'\n",
    "save_rating = r'./data_clean/rating.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08cea48-8e20-433b-ad67-5dd6b19ac0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b7bcc-208a-459b-a7db-65245f7a4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_data_files = [os.path.join(data_folder, i) for i in row_data_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e51560c-2254-49be-b33d-13a43075d4b2",
   "metadata": {},
   "source": [
    "### I. Создание табличных данных на основании txt файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88db14a-d515-4ee8-be4d-a4ee6de986b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_data_ops(\n",
    "    files: List[str],\n",
    "    save_file_name: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Creating table data from txt files\n",
    "    :param files: txt files names\n",
    "    :type files: list\n",
    "    :param save_file_name: file name for saving\n",
    "    :type save_file_name: str\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    for _, file_name in enumerate(files):\n",
    "        df = spark.read.text(os.path.join(file_name))\n",
    "        df = df.coalesce(1).withColumn(\"row_num\", F.monotonically_increasing_id())\n",
    "\n",
    "        df_partitions = df.select( F.col(\"row_num\").alias(\"Id\"), \n",
    "                                  F.regexp_extract(F.col(\"value\"), r'\\d+', 0).alias(\"Id_start\") ).where( F.substring(F.col(\"value\"), -1, 1)==\":\" )\n",
    "        df_partitions = df_partitions.select( F.col(\"Id\").cast('int'),\n",
    "                              F.col(\"Id_start\").cast('int'))\n",
    "\n",
    "        df_rows = df.select( F.col(\"row_num\").alias(\"Id\"),\n",
    "                             F.col(\"value\") ).where( F.substring(F.col(\"value\"), -1, 1)!=\":\" )\n",
    "        df_rows = df_rows.select( F.col(\"Id\"),\n",
    "                                  F.regexp_extract(F.col(\"value\"), r'(\\d+),(\\d+),(\\d+-\\d+-\\d+)', 1).cast('int').alias(\"user_Id\"),\n",
    "                                  F.regexp_extract(F.col(\"value\"), r'(\\d+),(\\d+),(\\d+-\\d+-\\d+)', 2).cast('int').alias(\"rating\"),\n",
    "                                  F.to_date(F.regexp_extract(F.col(\"value\"), r'(\\d+),(\\d+),(\\d+-\\d+-\\d+)', 3), \"yyyy-mm-dd\").alias(\"date\"))\n",
    "        df_partitions2 = df_partitions.select( F.col(\"Id\").alias(\"Id2\"),\n",
    "                                             F.col(\"Id_start\").alias(\"Id_end\"))\n",
    "        df_indexes = df_partitions.join(df_partitions2, df_partitions2.Id_end - df_partitions.Id_start == 1, \"left\").select( \n",
    "            F.col('Id').alias('Idx_start'), \n",
    "            F.col('Id2').alias('Idx_stop'),\n",
    "            F.col('Id_start').alias('Index'))\n",
    "\n",
    "        df_result = df_rows.join(F.broadcast(df_indexes), (df_rows.Id > df_indexes.Idx_start) & ((df_rows.Id < df_indexes.Idx_stop) | (df_indexes.Idx_stop.isNull())), \"inner\").select(\n",
    "            F.col('Index').alias('movie_Id'),\n",
    "            F.col('user_Id'),\n",
    "            F.col('rating'),\n",
    "            F.col('date')\n",
    "        ).distinct()\n",
    "        \n",
    "        if _ == 0:\n",
    "            df_all_users = df_result\n",
    "        else:\n",
    "            df_all_users = df_all_users.union(df_result)\n",
    "            \n",
    "    df_all_users.write.csv(save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25ad6e-c18e-4e7e-a7ee-2eaf80de0621",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_data_ops(row_data_files, save_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a164e5c-e723-4a45-96a3-1d84fd04221a",
   "metadata": {},
   "source": [
    "### II. Обработка фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033358f6-fdca-4872-b638-79db19f61725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def movies_ops(\n",
    "    data_path, \n",
    "    movies_path, \n",
    "    movie_save_path\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    operate movies name\n",
    "    :param data_path: path to netflix full file\n",
    "    :type data_path: str\n",
    "    :param movies_path: path to netflix movies file\n",
    "    :type movies_path: str\n",
    "    :param movie_save_path: file path to save clear netflix movies\n",
    "    :type movie_save_path: str\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    df_all = pd.read_csv(data_path)  \n",
    "    df_movies = pd.merge(df_all.groupby(by = ['movie_Id'], as_index=False).rating.count().rename(columns={'rating':'rating_cnt'}),\n",
    "                    df_all.groupby(by = ['movie_Id'], as_index=False).rating.mean().rename(columns={'rating':'rating_avg'}), \n",
    "                    on = 'movie_Id', how = 'inner')\n",
    "    \n",
    "    with open(movies_path, 'r', encoding=\"ISO-8859-1\") as f:\n",
    "        file = f.read()\n",
    "    file_arr = file.split('\\n')\n",
    "    \n",
    "    file_arr_id = []\n",
    "    file_arr_year = []\n",
    "    file_arr_name = []\n",
    "\n",
    "    file_arr_problem = []\n",
    "\n",
    "    for i in file_arr:\n",
    "        row = re.sub(r'^\\s+', '', i)\n",
    "        row = re.sub(r'\\s+$', '', i)\n",
    "        row_group = re.match(r'(\\d+),(\\d+),(.+)', row)\n",
    "        if row_group != None:\n",
    "            assert row == row_group.group(0)\n",
    "\n",
    "            file_arr_id.append(int(row_group.group(1)))\n",
    "            file_arr_year.append(int(row_group.group(2)))\n",
    "            file_arr_name.append(row_group.group(3))\n",
    "\n",
    "        else:\n",
    "            file_arr_problem.append(row)\n",
    "\n",
    "    \n",
    "    df_names = pd.DataFrame({ 'movie_Id':file_arr_id, 'year':file_arr_year, 'title':file_arr_name })\n",
    "    fill_na_year = ['2002', '2002', '2002', '1974', '1999', '1994', '1999']\n",
    "    fill_na_name = []\n",
    "    fill_na_id = []\n",
    "\n",
    "    for i in range(len(file_arr_problem)-1):\n",
    "        row_group = re.match(r'(\\d+),(NULL),(.+)', file_arr_problem[i])\n",
    "\n",
    "        fill_na_id.append(int(row_group.group(1)))\n",
    "        fill_na_name.append(row_group.group(3))\n",
    "\n",
    "    df_names = pd.concat([df_names, pd.DataFrame({ 'movie_Id':fill_na_id, 'year':fill_na_year, 'title':fill_na_name })])\n",
    "    df_names.movie_Id = df_names.movie_Id.astype('int')\n",
    "    df_names.year = df_names.year.astype('int')\n",
    "    \n",
    "    df_movies = pd.merge(df_movies, df_names, on = 'movie_Id', how = 'left')\n",
    "    df_movies.reset_index(drop=True).to_csv(movie_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344fe1df-ae89-47cb-b777-4d4214e86bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_ops(save_file_name, movie_titles_path, save_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa05a96-ddd8-4d92-82ec-d16145ecd774",
   "metadata": {},
   "source": [
    "### III. Обработка рейтингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d08d3b-f540-4b1b-8c81-7a2ac2d024fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_op(\n",
    "    data_path, \n",
    "    rating_save_path\n",
    "):\n",
    "    \"\"\"\n",
    "    operate ratings \n",
    "    :param data_path: path to netflix full file\n",
    "    :type data_path: str\n",
    "    :param rating_save_path: file path to save operated netflix ratings\n",
    "    :type rating_save_path: str\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    df_rating = pd.read_csv(data_path) \n",
    "    df_rating['timestamp'] = df_rating.date.apply(lambda x: pd.to_datetime(x))\n",
    "    df_rating['timestamp'] = df_rating.timestamp.apply(lambda x: x.timestamp())\n",
    "    df_rating = df_rating[['movie_Id', 'user_Id', 'rating', 'timestamp']]\n",
    "    \n",
    "    df_rating.reset_index(drop=True).to_csv(rating_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5744d2fd-2507-48f7-9081-69d9daa8a1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_op(save_file_name, save_rating)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-sber3.8]",
   "language": "python",
   "name": "conda-env-.conda-sber3.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
